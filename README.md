# 멀티캠퍼스 딥러닝 기반 AI 엔지니어링
2020.07.10 ~ 2020.12.23

## 1. <u>파이널 프로젝트</u> 복합 AI 서비스 시선입니다. (AI-Service)

:eye: 복합 AI 서비스 프로젝트 (우수상:star:)

> 시선 서비스는 전맹, 약맥 및 시각적으로 불편하신 분들의 새로운 눈이 되어 세상을 밝혀주고자 진행하게 된 복합 AI 서비스입니다.
>
> 현재 음성을 통한 "보여줘" , "읽어줘" 와 같은 기능을 지원하며 웹 어플리케이션 형태로 구현하였습니다.

- Team : A-eye

- Member : **김진원**(팀장), 민채정, 이동재, 박희원, 이찬주

- Duration : 2020.11.24 ~ 2020.12.23

------

최종 프로젝트는 드라마 "스타트업"에서 소개된 인공지능 스피커 "영실이"와 "눈길" 애플리케이션 에서 영감을 얻게 되어 팀을 구성하게 되었습니다.

- 프로젝트 "시선"은 "눈길"과 같이 시각이 불편하신 분들에게 조금 더 도움이 되었으면 하는 바람으로 진행되었습니다.

- 팀원을 구성할 때 그동안 알게 된 동료들의 강점을 파악하여 팀을 구성하게 되었습니다.

프로젝트 시작단계에서 모두 모바일 애플리케이션을 기대하였고 그에 따라 android와 IOS 두 기반에 모두 작동하는 애플리케이션을 개발하기 위해 혼합형 프레임워크인 Flutter를 활용해 보았습니다.

- 처음 접해보는 프레임워크인 관계로 배움과 조사하는데 3일 정도 소요되었습니다.
- 딥러닝 모델을 함께 활용하기 위해서는 서버를 통해서 작동하거나 경량화를 통해 장치에서 구현되어야 한다는 사실을 깨닫게 되었습니다.

- 멘토링을 통해 프로젝트 기간상 웹 애플리케이션으로 만드는 것이 적합하다는 결론을 지었습니다.

팀은 텍스트(김진원), 이미지 팀으로 나뉘었습니다.

- 텍스트 인식을 위해 사전 논문 조사를 진행하였고, 광학 문자 인식과 장면 문자 인식은 아직도 해결해야 할 과제가 많다는 것을 깨닫게 되었습니다.
- 강사님의 조언으로 Tesseract OCR을 활용하여 장면 문자 인식을 시도해 보았습니다.
- PyCharm 개발환경을 활용하여 원활한 텍스트 인식 개발을 위한 기반을 다져 두었습니다.
  - 문자 인식에 잘 작동하는 왜곡 수정 방법을 조사하여 구현해 내었습니다.
  - 광학 문자 인식 기반으로 진행된 장면 인식 성능은 장소와 찍는 방법에 따라서 정확도가 많이 달랐습니다.
- 더 나은 모델을 조사하던 중 네이버의 CRAFT 장면 문자 인식에 대해서 알게 되었고, 해당 기술을 활용해 보았으나, 구현하는 데에는 큰 노력과 시간이 소요되는 것을 예상하였습니다.

추가 기능으로 번역 모델을 생성하는 것을 팀원들과 구상하였습니다.

- Seq2Seq 신경망을 활용하여 영/한 번역모델을 만들어 보았지만 성능이 좋지 못했습니다.

모듈화 작업을 보조 하였습니다.

이미지 팀의 개발 상황을 알기 위해 모든 회의를 주관하였습니다.

팀원의 노력과 단합력 덕분에 프로젝트를 성공적으로 완성할 수 있었습니다.

<p align = "center"><a href="https://github.com/jw0831/Multicampus/tree/main/1.Final-project_seesun" title="seesun final project"><img src="README.assets/clickbutton.gif" width="120" height="100"></a></p>

## 2. <u>세미 2차 프로젝트</u> (CNN)

🏰 랜드마크 분류 프로젝트 (우수상:star:)

> SNS, 블로그, 이미지 검색서비스에서, 마음에 드는 장소를 찾기가 쉽지 않습니다. 이미지 인식 기반 랜드마크 분류 AI 기술을 통한 위치 찾기 서비스를 구현하여, 방문해보고 싶은 장소나 궁금한 장소에대한 위치를 쉽게 찾을 수 있습니다.

- Team : 여기요

- Member : **김진원**(팀장), 노용철, 홍세준, 민채정, 안애솔

- Duration : 2020.11.12 ~ 2020.11.23

------

수업에서 다룬 내용을 프로젝트를 통해서 최대한 많이 활용해 보기로 다짐하였습니다.

- 원활한 소통을 주도하였고, 좋은 아이디어가 나왔습니다.

렌드마크 분류 모델을 만들기 위해서 그동안 어떤 연구들이 선행되어 왔는지 조사하였습니다.

- 결과적으로 정확도 98% 의 모델을 생성할 수 있었습니다.

첫 이미지 분류 모델 생성인 만큼 해당 모델에 대해 더 알아보고 싶었습니다.

- ResNet-50 의 필터와 활성 채널 시각화를 진행하였습니다.
- 원본 이미지에 클래스 활성화 히트맵을 겹쳐보았습니다.

슬라이딩 윈도우를 통해 이미지 분류 모델을 탐지기로 만드는 방법을 알게되었습니다.

- 관련 소스코드를 조사하여 이미지 분류 모델을 탐지기로 만들어 보았습니다.
- 슬라이딩 윈도우를 통한 탐지 방법은 효율성과 시간이 많이 떨어지는것을 직접 채험하였고, 객체 탐지는 더 나은 방법으로 YOLO와 같은 Fully Convolutional Network를 활용해야 한다는 점을 깨달았습니다.

<p align = "center"><a href="https://github.com/jw0831/Multicampus/tree/main/2.Semi-project_2_Landmark_finder_using_CNN"><img src="README.assets/clickbutton.gif" width="120" height="100"></a></p>

## 3. <u>세미 1차 프로젝트</u> (NLP)

📰 텍스트 마이닝 프로젝트 (우수상:star:)

> 미국 대선 관련 뉴스 기사 & 트위터 & 토론 텍스트를 활용하여 기초적인 자연처 전처리 과정을 통해 감성 분석 및 대선 예측을 진행 👍 👎

- Team : 뽑아조
- Member : **김진원**(팀장/발표), 박지원, 이지윤, 이동재
- Duration : 2020.10.29~2020.11.11

------

멀티캠퍼스 과정에서 처음으로 팀장 자리를 맡게 되었습니다.

팀장은 팀원들보다 더 많이 생각하고, 모든 과정을 알아야 한다고 생각합니다.

- 원활한 프로젝트의 진행을 위해 자연어처리의 과정과 프로젝트의 방향성을 프로젝트를 진행하는 동안 지속해서 조사하였습니다.

선거 기간 동안 트위터의 API 승인이 늦춰질 것을 예상하였습니다.

- 트위터 크롤링 방법을 모색하여 데이터를 성공적으로 수집하였습니다.

각 후보와 사람들이 각 후보에게 보낸 트위터 메시지에 대해서, 자연어 처리와 시각화를 담당하였습니다.

감성 분석을 통한 수치 데이터를 기반으로, LSTM 신경망을 활용하여 선거 당일 포함 향후 5일에 대한 사람들의 감성지수를 예측해 보았습니다.

<p align = "center"><a href="https://github.com/jw0831/Multicampus/tree/main/3.Semi-project_1_text_mining_for_US_election_NLP"><img src="README.assets/clickbutton.gif" width="120" height="100"></a></p>

## 4. 멀티캠퍼스 연습 프로젝트

:heavy_dollar_sign:맛집 분석을 통해 합리적인 상권을 찾아라! 

> 제주도 맛집을 통한 상권 분석, 예측 맛집 **분석**
>
> 평점 데이터와 그 가게의 키워드들이 비례하는지 **예측**
>
> 가게의 리뷰들이 광고인지 리뷰인지 비교하여 평점 재 **산출**
>
> 많이 언급된 가게 근처에 어떤 상권들이 들어서고 나갔는지 **비교**

- Team : 제주사다수
- Member : 박희원(팀장), **김진원**, 이찬주, 조원우
- Duration : 2020.10.13~2020.10.22

------

팀원으로써 아이디어를 적극적으로 제안하였습니다.

인스타그램, 네이버 크롤링, 지도 시각화를 위한 데이터 전처리와 최종 산출물인 시각화를 진행하였습니다.

<p align = "center"><a href="https://github.com/jw0831/Multicampus/tree/main/4.호갱노노in제주"><img src="README.assets/clickbutton.gif" width="120" height="100"></a></p>

